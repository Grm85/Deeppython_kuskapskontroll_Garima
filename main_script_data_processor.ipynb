{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0ec8b-b995-47aa-972a-e7c4a32d1eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43937751-cf9f-4473-96e9-d14f19fc48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5857d54-c786-45bb-8455-3f8948b56c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up logging\n",
    "logging.basicConfig(filename='data_processing.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to log errors\n",
    "def log_error(error_message):\n",
    "    logging.error(f\"Error: {error_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435ac360-6a2c-47d1-b38b-13b43470836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV\n",
    "def load_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "        logging.info(\"CSV file loaded successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        log_error(f\"Failed to load CSV: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42274470-820c-4208-962d-3c9a0622ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Establish a connection to SQL Server\n",
    "def create_sql_connection(server, database):\n",
    "    try:\n",
    "        # Using SQLAlchemy to create an engine\n",
    "        engine = create_engine(f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "        conn = pyodbc.connect(\n",
    "            trusted_connected='yes',\n",
    "            DRIVER='SQL Server',\n",
    "            SERVER=server,\n",
    "            DATABASE=database   \n",
    "        )\n",
    "        logging.info(\"Connected to SQL Server successfully.\")\n",
    "        return conn, engine\n",
    "    except Exception as e:\n",
    "        log_error(f\"Failed to connect to SQL Server: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a829320-de9b-42eb-82e3-fd399d7708f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch data from the SQL table\n",
    "def fetch_data_from_sql(conn, table_name):\n",
    "    try:\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df_sql = pd.read_sql(query, conn)\n",
    "        logging.info(f\"Data fetched from {table_name} successfully.\")\n",
    "        return df_sql\n",
    "    except Exception as e:\n",
    "        log_error(f\"Failed to fetch data from SQL: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146e79b7-de51-4717-9587-cba2b19f5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data cleaning\n",
    "def clean_data(df_sql):\n",
    "    try:\n",
    "        # Dropping the 'Unnamed' and 'Status' columns\n",
    "        df_sql.drop(columns=['Unnamed', 'Status'], inplace=True, errors='ignore')\n",
    "\n",
    "        # Renaming 'nage' to 'age_group'\n",
    "        df_sql.rename(columns={'nage': 'age_group'}, inplace=True)\n",
    "\n",
    "        # Dropping duplicates\n",
    "        df_sql.drop_duplicates(inplace=True)\n",
    "\n",
    "        # Resetting the index\n",
    "        df_sql.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        logging.info(\"Data cleaning and transformation completed successfully.\")\n",
    "        return df_sql\n",
    "    except Exception as e:\n",
    "        log_error(f\"Data cleaning failed: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af25b87-bb31-4a73-a5aa-948541a5f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the updated data back to the SQL Server\n",
    "def save_data_to_sql(df, engine, table_name):\n",
    "    try:\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        logging.info(f\"Data saved back to {table_name} successfully.\")\n",
    "    except Exception as e:\n",
    "        log_error(f\"Failed to save data to SQL Server: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a837ab-a015-4882-aa3d-955c220f61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to execute the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1f07a0-e741-43f7-abee-aff613307b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_34620\\2818388162.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sql = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    csv_file_path = r\"C:\\Users\\LENOVO\\OneDrive\\Desktop\\deeppython\\Python_Diwali_Sales_Analysis-main\\data processor\\Diwali.csv\"\n",
    "    server = 'LAPTOP-U3795DN8'\n",
    "    database = 'mydatabase'\n",
    "    table_name = 'dbo.Diwali'\n",
    "\n",
    "    # Load CSV data\n",
    "    df = load_csv(csv_file_path)\n",
    "\n",
    "    # Connect to SQL Server\n",
    "    conn, engine = create_sql_connection(server, database,)\n",
    "\n",
    "    # Fetch data from SQL\n",
    "    df_sql = fetch_data_from_sql(conn, table_name)\n",
    "\n",
    "    # Clean data\n",
    "    cleaned_df = clean_data(df_sql)\n",
    "\n",
    "    # Save the cleaned data back to SQL\n",
    "    save_data_to_sql(cleaned_df, engine, table_name)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    logging.info(\"Database connection closed.\")\n",
    "\n",
    "def create_sql_connection(server, database):\n",
    "    conn_str = (\n",
    "        f\"Driver={{ODBC Driver 17 for SQL Server}};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        \"Trusted_Connection=yes;\"\n",
    "    )\n",
    "    engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={urllib.parse.quote_plus(conn_str)}\")\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    return conn, engine\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70d038-7835-44ec-af59-f5f245d312b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e4152-d654-4b47-884b-97ae3cbad47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
